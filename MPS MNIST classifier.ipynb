{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPS classifier using TensorNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "https://papers.nips.cc/paper/6211-supervised-learning-with-tensor-networks.pdf\n",
    "\n",
    "https://tensornetwork.readthedocs.io/en/latest/index.html\n",
    "\n",
    "To do:\n",
    "        - Change SVD calculation\n",
    "        \n",
    "        - more efficient calculation of projection phit\n",
    "        \n",
    "        - Initialization\n",
    "        \n",
    "        - Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import tensornetwork as tn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to encode the data set into a tensor to be contracted with the MPS network. Consider inputs which are grayscale images with $N = 28\\times 28$ pixels. The value of pixel number $j=1,...,N$ is $x_j\\in[0,1]$. A simple (and arbitrary) choice for the local feature map $\\phi$ is\n",
    "\n",
    "$ \\phi^{s_j}(x_j) = \\left[\\cos\\left(\\frac{\\pi}{2}x_j\\right),\\sin\\left(\\frac{\\pi}{2}x_j\\right)\\right], \\quad s_j=1,2  $\n",
    "\n",
    "The **feature map** $\\Phi$ is defined as the rank $N$ tensor product\n",
    "\n",
    "$ \\Phi^{s_1s_2\\ldots s_N}(x) = \\phi^{s_1}(x_1)\\otimes \\phi^{s_2}(x_2) \\otimes \\ldots \\otimes \\phi^{s_N}(x_N)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_map(X):\n",
    "    # Input: X of shape (Nt, N)\n",
    "    # Output: Feature map Phi of shape (Nt, N, 2)\n",
    "\n",
    "    Phi = np.array([np.cos(np.pi*X/2), np.sin(np.pi*X/2)])\n",
    "    Phi = np.transpose(Phi, (1, 2, 0))\n",
    "    \n",
    "    return Phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  - Feature map example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7, 2)\n"
     ]
    }
   ],
   "source": [
    "# Make up data as Nt = 5 images with N = 7 pixels\n",
    "X_example = np.random.rand(5, 7)\n",
    "\n",
    "# Feature map is a (Nt, N) matrix\n",
    "Phi_example = feature_map(X_example)\n",
    "\n",
    "print(Phi_example.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider an MPS decomposition of the weight tensor $W^l$ of the form\n",
    "\n",
    "$ W^l_{s_1s_2\\ldots s_N} = \\sum_{\\{\\alpha\\}} A_{s_1}^{\\alpha_1}A_{s_2}^{\\alpha_1\\alpha_2}\\ldots A_{s_j}^{l;\\alpha_j \\alpha_{j+1}}\\ldots A_{s_N}^{\\alpha_{N-1}}  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MPS(N, D):\n",
    "    # Input\n",
    "    #    N: number of features\n",
    "    #    D: bond dimension (alphaj = 1,...,D)\n",
    "    # Output\n",
    "    #    mps: an array of N sites [mps[0],mps[1],...,mps[N-1]] \n",
    "    #         where each site represents a rank 3-tensors initialized randomly\n",
    "    # indices (a,b,c) are organized as (left, down, right)\n",
    "     \n",
    "    # Create N-1 sites of the MPS\n",
    "    mps = [np.random.uniform(-1.5, 1.5, (D, 2, D)) for i in range(N-1)]\n",
    "    # Add first site with extra label index l: (left, down, right, l)\n",
    "    mps.insert(0, np.random.uniform(-1.5, 1.5, (D, 2, D, 10)))\n",
    "  \n",
    "    return mps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - MPS example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.18612287,  0.50906668,  1.16090788, -0.02869681,\n",
       "          -0.27371857, -0.82661807,  0.39550064, -0.84340475,\n",
       "           0.17841562,  1.4812135 ]],\n",
       "\n",
       "        [[-1.40883364, -1.10815067,  1.17457275,  1.39323325,\n",
       "          -1.271777  , -1.21466379,  0.95371517, -0.11401598,\n",
       "           0.65596548,  1.23067002]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test MPS with N=3 and D=1\n",
    "mps_example = MPS(3,1)\n",
    "\n",
    "# First mps site\n",
    "mps_example[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of first node: (1, 2, 1, 10)\n",
      "Shape of second node: (1, 2, 1)\n",
      "Shape of last node: (1, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of first node:\", mps_example[0].shape)\n",
    "print(\"Shape of second node:\", mps_example[1].shape)\n",
    "print(\"Shape of last node:\", mps_example[-1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projected input $\\tilde\\Phi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The projected input $\\tilde{\\Phi}$ is obtained by removing the nodes at sites $j$ and $j+1$ from the mps and contracting it with the feature tensor. Since the $j$th and $(j+1)$th index of the feature tensor are not contracted, the resulting tensor $\\tilde{\\Phi}$ is a rank 4 tensor. We will need $\\tilde{\\Phi}$ to compute the decision function $f^l(x_n)$ and the cost function $C$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_n(mps, Phi, n, j):\n",
    "    # Input: mps array\n",
    "    #        Feature tensor Phi with shape (Nt,N)\n",
    "    #        Index  n = 1,...,NT of the training example   \n",
    "    #        Index j of the site that carries the label l\n",
    "    # Output: P with index order (sj, s(j+1), alpha(j+1), alpha(j-1))\n",
    "    \n",
    "    N = len(mps)\n",
    "    \n",
    "    mps_site = tn.Node(mps[j-1]) # convert arrays to Nodes of TensorNetwork\n",
    "    Phi_site = tn.Node(Phi[n, j-1])\n",
    "    \n",
    "    # Contract mps site with respective feature vector phi\n",
    "    P = tn.contract(mps_site[1] ^ Phi_site[0]) # has indices (alpha(j-2), alpha(j-1))\n",
    "    \n",
    "    for k in reversed(range(j-N+2, j-1)):              # Start from j-1, going to the left\n",
    "        mps_site = tn.Node(mps[k]) \n",
    "        Phi_site = tn.Node(Phi[n, k])\n",
    "        pair = tn.contract(mps_site[1] ^ Phi_site[0])  # Contract MPS with respective phi  \n",
    "        P = tn.contract(pair[1] ^ P[0])                # Contract with previous result\n",
    "\n",
    "    Phi_site1 = tn.Node(Phi[n, (j+1) % N])\n",
    "    Phi_site2 = tn.Node(Phi[n, j])\n",
    "    \n",
    "    P = tn.outer_product(Phi_site1, P) # Add phi(sj+1)\n",
    "    P = tn.outer_product(Phi_site2, P) # Add(phi(sj))\n",
    "    \n",
    "    # At this point P has indices (alpha(j+1), alpha(j-1))\n",
    "    \n",
    "    P.tensor = P.tensor/tn.norm(P) # Normalize\n",
    "    \n",
    "    return P.tensor\n",
    "\n",
    "def projection(mps, Phi, j):\n",
    "    # Output Phit with index order (n, sj, s(j+1), alpha(j+1), alpha(j-1))\n",
    "    Nt = Phi.shape[0]\n",
    "    proj = np.array([proj_n(mps, Phi, n, j) for n in range(Nt)])\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Projection example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mps_example = MPS(7, 3)              # MPS with N=7 features and D=3 bond dimension\n",
    "X_example = np.random.rand(5, 7)     # Training data with Nt=5 examples\n",
    "Phi_example = feature_map(X_example) # The feature map of shape (Nt, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2, 2, 3, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phit_example = projection(mps_example, Phi_example, 0)\n",
    "Phit_example.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the algorithm, we will obtain an improved $B$, and we want to decompose it using SVD to restore the original MPS form. Treat $B^l$ as a matrix with collective row index $(\\alpha_{j-1},s_j)$ and collective column index $(l,\\alpha_j,s_j+1)$. The SVD of $B^l$ gives\n",
    "\n",
    "$ B_{s_js_{j+1}}^{\\alpha_{j-1}l\\alpha_{j+1}} = \\sum_{\\alpha'_j \\alpha_j}U_{s_j\\alpha'_{j}}^{\\alpha_{j-1}} S_{\\ \\ \\alpha_j}^{\\alpha'_j} V_{s_{j+1}}^{\\alpha_j l\\alpha_{j+1}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(B, Dmax):\n",
    "    # Apply SVD to B which is a rank 5-tensor indexed as [alpha(j-1), sj, l, s(j+1), alpha(j+1)]\n",
    "    # Dmax is the max number of singular values we keep\n",
    "    \n",
    "    B_node = tn.Node(B)\n",
    "    \n",
    "    U, Vh, truncation_error = tn.split_node(B_node, \n",
    "                                            left_edges=[B_node[0],B_node[1]],\n",
    "                                            right_edges=[B_node[3],B_node[4],B_node[2]],\n",
    "                                            max_singular_values=Dmax)\n",
    "    \n",
    "    # Return U = u sqrt(S), Vh = sqrt(S) vh\n",
    "    # In Stoudenmire and Schwab paper, S is entirely part of Vh\n",
    "    # Index form is U[alpha(j-1), sj, bond] and Vh[bond, s(j+1), alpha(j+1), l]\n",
    "    return U.tensor, Vh.tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  - SVD example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 7, 5)\n",
      "(5, 20, 30, 10)\n"
     ]
    }
   ],
   "source": [
    "# Example of SVD applied to a rank 5 tensor with dimensions (4,7,10,20,30)\n",
    "# We split it by keeping 5 largest singular values\n",
    "B_random = np.random.rand(4, 7, 10, 20, 30)\n",
    "U_random, Vh_random = split(B_random, 5)\n",
    "\n",
    "print(U_random.shape)\n",
    "print(Vh_random.shape) # label l is now the last index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision function is computed from the projected input $\\tilde{\\Phi}_n$ and the current bond tensor $B^l$ as\n",
    "\n",
    "$f^l(x_n) = \\sum_{\\alpha_{j-1}\\alpha_{j+1}}\\sum_{s_{j}s_{j+1}} B_{s_js_{j+1}}^{\\alpha_{j-1}l\\alpha_{j+1}}\\left(\\tilde{\\Phi}_n\\right)^{s_js_{s+1}}_{\\alpha_{j-1}\\alpha_{j+1}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision(B, Phit):\n",
    "    # B tensor with index order [alpha(j-1), sj, l, s(j+1), alpha(j+1)]\n",
    "    # Phit tensor with index order [n, sj, s(j+1), alpha(j+1), alpha(j-1)] \n",
    "      \n",
    "    B_node = tn.Node(B)        \n",
    "    Phit_node = tn.Node(Phit) \n",
    "    \n",
    "    # Take contraction of alpha and s indices\n",
    "    B_node[0] ^ Phit_node[4] # alpha(j-1) \n",
    "    B_node[4] ^ Phit_node[3] # alpha(j+1)\n",
    "    B_node[1] ^ Phit_node[1] # sj\n",
    "    B_node[3] ^ Phit_node[2] # s(j+1)\n",
    "    \n",
    "    # f is a matrix with shape (NT, 10)\n",
    "    f = Phit_node @ B_node # This is the same as tn.contract_between(B_copy, Phit_copy)\n",
    "\n",
    "    return f.tensor # Output is not a Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function is given by\n",
    "\n",
    "$ C = \\frac{1}{2}\\sum_{n=1}^{N_T}\\sum_l\\left(f^l(x_n)-y_n^l\\right)^2$\n",
    "\n",
    "If correct label of $x_n$ is $L_n$, then $y_n^{L_n}=1$ and $y_n^l=0$ otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(f, y):\n",
    "    # f is a matrix with shape (Nt, 10)\n",
    "    # y is a matrix with shape (Nt, 10)\n",
    "    diff = (f-y).flatten()\n",
    "    C = (1/2)*np.sum(np.square(diff))\n",
    "    \n",
    "    return C # Output is a scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of the cost is given by (the full index structure is being omitted)\n",
    "\n",
    "$\\Delta B^l = -\\frac{\\partial C}{\\partial B^l} = \\sum_{n=1}^{N_T}(y_n^l-f^l(x_n))\\tilde{\\Phi}_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(Phit, y, f):  \n",
    "    # Phit has form Phit(n, sj, s(j+1), alpha(j+1), alpha(j-1))\n",
    "    # f and y are matrices with shape (NT, 10)\n",
    "    # grad has the same index structure as B: (alpha(j-1), sj, l, s(j+1), alpha(j+1))\n",
    "    NT = y.shape[0]   \n",
    "    diff = (y - f) \n",
    "    grad = 0\n",
    "    \n",
    "    node1 = tn.Node(diff)\n",
    "    node2 = tn.Node(Phit)\n",
    "    grad = tn.contract(node1[0] ^ node2[0])\n",
    "    \n",
    "    grad.tensor = np.transpose(grad.tensor, (4, 1, 0, 2, 3)) # Reorganize indices      \n",
    "    \n",
    "    return grad.tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001       # 'Learning rate' to update B\n",
    "Nt = 500         # Number of training examples \n",
    "Ny = 50          # Number of test examples\n",
    "img_len = 14     # size of image\n",
    "N = img_len**2   # Number of features (pixels)\n",
    "Nsweep = 2       # Number of passes through the mps\n",
    "D = 2            # Initial bond dimension of the mps\n",
    "Dmax = 10        # Maximal bond dimension after SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data set shape: (60000, 28, 28)\n",
      "Training set shape: (500, 196)\n",
      "Test set shape: (50, 196)\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset using keras\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize dataset such that X contain values between 0 and 1\n",
    "X_train, X_test = X_train_full[:Nt]/255.0, X_train_full[Nt+1:Nt+1+Ny]/255.0\n",
    "y_train, y_test = y_train_full[:Nt], y_train_full[Nt+1:Nt+1+Ny]\n",
    "\n",
    "# Downscale images to 14x14\n",
    "X_train = np.array([resize(X_train[i], (img_len, img_len)) for i in range(Nt)])\n",
    "X_test = np.array([resize(X_test[i], (img_len, img_len)) for i in range(Ny)])\n",
    "\n",
    "# Reshape (14, 14) into (196)\n",
    "X_train = X_train.reshape(X_train.shape[0], N)\n",
    "X_test = X_test.reshape(X_test.shape[0], N)\n",
    "\n",
    "ymatrix = []\n",
    "for n in range(Nt):\n",
    "    yarray = np.zeros(10)\n",
    "    yarray[y_train[n]] = 1\n",
    "    ymatrix.append(yarray)\n",
    "    \n",
    "y_train = np.array(ymatrix)\n",
    "\n",
    "ymatrix = []\n",
    "for n in range(Ny):\n",
    "    yarray = np.zeros(10)\n",
    "    yarray[y_test[n]] = 1\n",
    "    ymatrix.append(yarray)\n",
    "\n",
    "y_test = np.array(ymatrix)\n",
    "\n",
    "print(\"Full data set shape:\", X_train_full.shape)\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example data image\n",
    "some_digit_image = X_train[np.random.randint(Nt)].reshape(img_len, img_len)\n",
    "plt.imshow(some_digit_image, cmap=\"binary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training data\n",
    "X = X_train\n",
    "\n",
    "# Set training labels\n",
    "y = y_train\n",
    "\n",
    "# The feature map with shape (Nt, N)\n",
    "Phi = feature_map(X)\n",
    "\n",
    "# Initialize MPS with N features and D bond dimension\n",
    "mps = MPS(N, D)\n",
    "\n",
    "for k in range(Nsweep):\n",
    "    # Start from first site of the mps \n",
    "    for j in range(N):\n",
    "\n",
    "        \n",
    "        # Take sites j and j+1\n",
    "        A1 = tn.Node(mps[j])\n",
    "        A2 = tn.Node(mps[(j+1) % N])\n",
    "\n",
    "        # calculate B which is the contraction of the two sites\n",
    "        B = tn.contract(A1[2] ^ A2[0]).tensor\n",
    "\n",
    "        # The projection Phit obtained when we remove A1 and A2\n",
    "        Phit = projection(mps, Phi, j)  # Phi has shape (7,2,2,D,D)\n",
    "\n",
    "        # Contraction of feature map with mps gives the cost\n",
    "        f = decision(B, Phit) # f has shape(Nt,10)\n",
    "\n",
    "        # Compute cost\n",
    "        C = cost(f, y)\n",
    "        \n",
    "\n",
    "        # Computed gradient to update B\n",
    "        dB = grad(Phit, y, f)\n",
    "\n",
    "        B = B + lr * dB\n",
    "\n",
    "        # Split updated B into two nodes to restore MPS form\n",
    "        mps[j], mps[(j+1) % N] = split(B, Dmax)\n",
    "        \n",
    "        # At the end of the loop, mps[0] gets the index l back to start a new sweep\n",
    "        \n",
    "        if j % 10 == 0:\n",
    "            accuracy = 0\n",
    "            for n in range(Nt):\n",
    "                if np.argmax(f[n]) == np.argmax(y[n]):\n",
    "                    accuracy = accuracy + 1\n",
    "            accuracy = accuracy/Nt\n",
    "\n",
    "            # The feature map with shape (Nt, N)\n",
    "            Phi_test = feature_map(X_test)\n",
    "            A1 = tn.Node(mps[0])\n",
    "            A2 = tn.Node(mps[1])\n",
    "            B_test = tn.contract(A1[2] ^ A2[0]).tensor\n",
    "            Phit_test = projection(mps, Phi_test, j) \n",
    "            f_test = decision(B, Phit_test) \n",
    "\n",
    "            test_accuracy = 0\n",
    "            for n in range(Ny):\n",
    "                if np.argmax(f_test[n]) == np.argmax(y_test[n]):\n",
    "                    test_accuracy = test_accuracy + 1\n",
    "\n",
    "            test_accuracy = test_accuracy/Ny\n",
    "            print (\"Sweep %d,   MPS site %d,  Cost = %f\" % (k, j, C)) \n",
    "            print(\"Training accuracy:\", accuracy)\n",
    "            print(\"Test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
